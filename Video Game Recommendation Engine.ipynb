{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "* Gather the data using Giant Bomb API.\n",
    "* Complete exploratory data analysis.\n",
    "* Analyze recommendation methods.\n",
    "\n",
    "## Background Information\n",
    "* With the number of products increasing exponentially, it burdens the consumer in which products to purchase. A novel solution is the use of recommender systems (engines) to \"recommend\" relevant products to the consumers based on their preferences. Applications of recommender systems include areas such as playlist generators for video and music services like Netflix, YouTube, and Spotify. Additionally, product recommendations for services such as Amazon. In this project, we'll explore novel techniques in recommending video games using the Giant Bomb video game database. \n",
    "\n",
    "## Process:\n",
    "* Preprocessing (NLP packages)\n",
    "* Exploratory Data Analysis conducted utilizing various python packages (Numpy, Matplotlib, Pandas, and Plotly).'\n",
    "* Recommendation Methods.\n",
    "    * TF-IDF\n",
    "        * Cosine Similarity\n",
    "        * Cosine Similarity + Singular Value Decomposition\n",
    "        * K-Nearest Neighbors\n",
    "        * K-Nearest Neighbors + Singular Value Decomposition\n",
    "* PostgreSQL database.\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents:\n",
    "* Part I: Data Exploration\n",
    "    * Gathering\n",
    "    * Preprocessing\n",
    "    * Exploration\n",
    "* Part II: Recommendation Methods\n",
    "    * TF-IDF\n",
    "    * Cosine Similarity\n",
    "    * KNN\n",
    "    * SVD\n",
    "        * Cosine Similarity\n",
    "        * KNN\n",
    "    * Results\n",
    "* Part III: PostgreSQL database for application deployment.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pybomb\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "params = {'text.usetex': False, 'mathtext.fontset': 'stixsans'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by fetching the identifiers (ID's) of PC video games and store it into a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pulls video game ID's from giantbomb.\"\"\"\n",
    "\n",
    "# Store various video game features into a list\n",
    "## Despite only needing the video game ID's, we'll take other features to compare.\n",
    "name_list = []\n",
    "image_url_list = []\n",
    "id_list = []\n",
    "original_game_rating_list = []\n",
    "original_release_date_list = []\n",
    "platforms_list = []\n",
    "\n",
    "\n",
    "# Request video game contents from the giantbomb api\n",
    "## Instantiate it with a loop of getting 100 games at a time up to 50000\n",
    "for x in range(100, 50000, 100):\n",
    "    ## API Key\n",
    "    my_key = 'f3e0c1a5f79182d471034230dd277db19eb873ef'\n",
    "    ## API fields\n",
    "    games_client = pybomb.GamesClient(my_key)\n",
    "    return_fields = ('id', 'name', 'image', 'platforms', 'original_release_date',  'original_game_rating')\n",
    "    limit = 100\n",
    "    offset = x\n",
    "    sort_by = 'name'\n",
    "    filter_by = {'platforms': pybomb.PC}\n",
    "    \n",
    "    ## Now we pull the games and store it in the response\n",
    "    response = games_client.search(\n",
    "        filter_by = filter_by,\n",
    "        return_fields = return_fields,\n",
    "        sort_by = sort_by,\n",
    "        desc = False,\n",
    "        limit = limit,\n",
    "        offset = offset\n",
    "    )\n",
    "    ## Iterate through the response.results and store the features into lists\n",
    "    for x in response.results:\n",
    "        ### Features\n",
    "        name_list.append(x['name'])\n",
    "        image_url_list.append(x['image']['super_url'])\n",
    "        id_list.append(x['id'])\n",
    "        original_release_date_list.append(x['original_release_date'])\n",
    "        platforms_list.append('PC')\n",
    "        ### Append original game rating feature if it exists, if it not it's none\n",
    "        if x['original_game_rating'] == None:\n",
    "            original_game_rating_list.append('None')\n",
    "        else:\n",
    "            original_game_rating_list.append(x['original_game_rating'][0]['name'])\n",
    "\n",
    "# Export id list as csv\n",
    "data =  {'id': id_list}\n",
    "\n",
    "tmp_df = pd.DataFrame(data)\n",
    "\n",
    "tmp_df.to_csv('data/id_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll fetch the contents of the video games using the ID's and then storing it into our final csv file for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = pd.read_csv('data/id_list.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pulls video game contents using the video game id's collected previously.\"\"\"\n",
    "# Load in ID CSV\n",
    "id_list = pd.read_csv('data/id_list.csv', index_col = 0)\n",
    "\n",
    "# Store various video game features into a list\n",
    "name_list = []\n",
    "image_url_list = []\n",
    "original_game_rating_list = []\n",
    "original_release_date_list = []\n",
    "platforms_list = []\n",
    "developers_list = []\n",
    "genres_list = []\n",
    "themes_list = []\n",
    "concepts_list = []\n",
    "franchises_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Request video game contents from the giantbomb api\n",
    "## Giantbomb api has a maximum number of requests per hour, we'll utilize the time commands to limit our requests per hour while being automated\n",
    "counter = 0\n",
    "for i in id_list['id']:\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    ## If counter does not equal to 0\n",
    "    if counter % 1000 != 0:\n",
    "        ## Sleep for two seconds\n",
    "        time.sleep(2)\n",
    "        ## Take a maximum of 10 tries before returning an error.\n",
    "        incomplete = True\n",
    "        tries = 10\n",
    "        while incomplete and tries > 0:\n",
    "            try:\n",
    "                ## API Key\n",
    "                my_key = 'f3e0c1a5f79182d471034230dd277db19eb873ef'\n",
    "                game_client = pybomb.GameClient(my_key)\n",
    "                ## API fields\n",
    "                game_id = i\n",
    "                return_fields = ('id', 'name',\n",
    "                                 'genres', 'themes',\n",
    "                                 'franchises', 'developers',\n",
    "                                 'platforms', 'original_release_date',\n",
    "                                 'original_game_rating', 'image')\n",
    "                ## Now we pull the games and store it in the response\n",
    "                response = game_client.fetch(game_id)\n",
    "            \n",
    "                \n",
    "                ## Store the response.results contents into their respective feature list\n",
    "                ### Name\n",
    "                if ('name' in response.results) & (response.results['name'] != None):\n",
    "                    name_list.append(response.results['name'])\n",
    "                else:\n",
    "                    name_list.append('None')\n",
    "\n",
    "                ### Image URL\n",
    "                if ('image' in response.results) & ('super_url' in response.results['image']) & (response.results['image']['super_url'] != None):\n",
    "                    image_url_list.append(response.results['image']['super_url'])\n",
    "                else:\n",
    "                    image_url_list.append('None')\n",
    "\n",
    "                ### Original Release Date\n",
    "                if ('original_release_date' in response.results) & (response.results['original_release_date'] != None):\n",
    "                    original_release_date_list.append(response.results['original_release_date'])\n",
    "                else:\n",
    "                    original_release_date_list.append('None')\n",
    "\n",
    "                ### Original Game Rating \n",
    "                if ('original_game_rating' in response.results) & (response.results['original_game_rating'] != None):\n",
    "                    original_game_rating_list.append(response.results['original_game_rating'][0]['name'])\n",
    "                else:\n",
    "                    original_game_rating_list.append('None')\n",
    "\n",
    "                ### Platform\n",
    "                if ('platforms' in response.results) & (response.results['platforms'] != None):\n",
    "                    platforms_list.append(response.results['platforms'][0]['name'])\n",
    "                else:\n",
    "                    platforms_list.append('None')\n",
    "\n",
    "                ### Developers\n",
    "                if ('developers' in response.results) & (response.results['developers'] != None):\n",
    "                    developers_list.append(response.results['developers'][0]['name'])\n",
    "                else:\n",
    "                    developers_list.append('None')\n",
    "\n",
    "                ### Genres\n",
    "                tmp_list = []\n",
    "                if ('genres' in response.results):\n",
    "                    if (response.results['genres'] != None):\n",
    "                        for x in response.results['genres']:\n",
    "                            tmp_list.append(x['name'])\n",
    "                        genres_list.append(tmp_list)\n",
    "                    else:\n",
    "                        genres_list.append('None')\n",
    "                else:\n",
    "                    genres_list.append('None')\n",
    "\n",
    "\n",
    "\n",
    "                ### Concepts\n",
    "                tmp_list = []\n",
    "                if ('concepts' in response.results):\n",
    "                    if (response.results['concepts'] != None):\n",
    "                        for x in response.results['concepts']:\n",
    "                            tmp_list.append(x['name'])\n",
    "                        concepts_list.append(tmp_list)\n",
    "                    else:\n",
    "                        concepts_list.append('None')\n",
    "                else:\n",
    "                    concepts_list.append('None')\n",
    "\n",
    "\n",
    "                ### Themes\n",
    "                tmp_list = []\n",
    "                if ('themes' in response.results):\n",
    "                    if (response.results['themes'] != None):\n",
    "                        for x in response.results['themes']:\n",
    "                            tmp_list.append(x['name'])\n",
    "                        themes_list.append(tmp_list)\n",
    "                    else:\n",
    "                        themes_list.append('None')\n",
    "                else:\n",
    "                    themes_list.append('None')\n",
    "\n",
    "\n",
    "\n",
    "                ### Franchises\n",
    "                tmp_list = []\n",
    "                if 'franchises' in response.results:\n",
    "                    if (response.results['franchises'] != None):\n",
    "                        for x in response.results['franchises']:\n",
    "                            tmp_list.append(x['name'])\n",
    "                        franchises_list.append(tmp_list)\n",
    "                    else:\n",
    "                        franchises_list.append('None')\n",
    "\n",
    "                else:\n",
    "                    franchises_list.append('None')\n",
    "                    \n",
    "                incomplete = False\n",
    "            except:\n",
    "                tries -=1\n",
    "                \n",
    "        if incomplete == True:\n",
    "            print('It is failing a lot')\n",
    "        \n",
    "        else:\n",
    "            print('Success')\n",
    "\n",
    "    else:\n",
    "        # If the counter equals 1, take a 10 minute break.\n",
    "        time.sleep(600)\n",
    "        \n",
    "        \n",
    "# Export video game dataframe as a csv\n",
    "data =  {'id': id_list,\n",
    "         'name': name_list,\n",
    "         'original_game_rating': original_game_rating_list, \n",
    "         'original_release_date_': original_release_date_list,\n",
    "         'platform': name_list,\n",
    "         'developer': developers_list,\n",
    "         'genre': genres_list,\n",
    "         'theme': themes_list,\n",
    "         'concept': concepts_list,\n",
    "         'franchise': franchises_list,\n",
    "         'image_url': image_url_list}\n",
    "\n",
    "tmp_df = pd.DataFrame(data)\n",
    "\n",
    "tmp_df.to_csv('data/fetched_video_games.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin by reading in the CSV file containing the data, and examining the data contents such as the number of features and the number of samples. It seems there are 11 column entries (features) and 33403 row entries (number of samples).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fetched_video_games.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing including a few steps:\n",
    "\n",
    "(1) Filter out entries that do not have a genre, theme, and concept value.\n",
    "\n",
    "(2) Drop entries that contain adult and adult values.\n",
    "\n",
    "(3) Text Processing\n",
    "    * Convert the fields from objects into strings.\n",
    "    * All fields with no values were labeled as None.\n",
    "    * Strip the quotation marks.\n",
    "    * Remove whitespace between strings\n",
    "    * Adjust entries with multiple descriptors. \n",
    "(4) Creation of our feature inputted into our algorithms, which is the concatenation of the game rating (Age elibility), developer, genre, theme, concept, and franchise.\n",
    "\n",
    "Those features were selected for the following reasons:\n",
    "\n",
    "* If a game is given a game rating (age rating) do not want to recommend games that are not suitable for the user.\n",
    "\n",
    "* If a user enjoys a game, they may enjoy a game from the same developer and franchise.\n",
    "\n",
    "* Genre, theme, and concept features all relate to the atmosphere and environment of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NONE(x):\n",
    "    \"\"\"Function to label a column as None if there are no contents.\"\"\"\n",
    "    if x == 'None':\n",
    "        x = ''\n",
    "        return x \n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Drop entries that don't have a genre, theme, and concept value.\n",
    "df = df.loc[(df['genre'] != 'None') & (df['theme'] != 'None') & (df['concept'] != 'None')].copy()\n",
    "\n",
    "## Drop entries that are related to anime and adult.\n",
    "df = df[(~df['theme'].str.contains(\"Anime\")) & (~df['theme'].str.contains(\"Adult\"))]\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "## Apply text processing across various columns.\n",
    "column_list = ['original_game_rating', 'original_release_date_', 'platform',\n",
    "               'developer', 'genre', 'theme', 'concept', 'franchise']\n",
    "#for x in df.columns[2:]:\n",
    "for x in column_list:\n",
    "    df[x] = df[x].apply(str)\n",
    "    \n",
    "    \n",
    "    ## If a column has no contents, it is labeled as none.\n",
    "    df[x] = df[x].apply(NONE)\n",
    "    \n",
    "    \n",
    "    ## Remove Brackets\n",
    "    df[x] = df[x].apply(lambda i: i.strip('[]'))\n",
    "    \n",
    "    ## Strip quotation marks\n",
    "    df[x] = df[x].apply(lambda i: i.strip(\"''\"))\n",
    "    df[x] = df[x].apply(lambda i: i.strip('\"\"'))\n",
    "    df[x] = df[x].apply(lambda i: re.sub('\"', '', i))\n",
    "    df[x] = df[x].apply(lambda i: re.sub(\"'\", '', i))\n",
    "        \n",
    "    ## Remove Whitespace between multiple string values\n",
    "    df[x] = df[x].apply(lambda i: i.replace('  ', ' '))  \n",
    "\n",
    "    # Fix ','\n",
    "    df[x] = df[x].apply(lambda i: i.replace(\"','\", ' '))\n",
    "\n",
    "    # Fix \",\"\n",
    "    df[x] = df[x].apply(lambda i: i.replace('\",\"', ' '))\n",
    "    df[x] = df[x].apply(lambda i: i.replace(',', ' '))\n",
    "    \n",
    "    # Fix Genre Action Adventure\n",
    "    \n",
    "    # Fix '-'\n",
    "    df[x] = df[x].apply(lambda i: i.replace('-', ' '))\n",
    "    \n",
    "    \n",
    "\n",
    "# Total Content Description\n",
    "df['total_contents'] = df['original_game_rating'] + \" \" + df['developer'] + \" \" + df['genre'] + \" \" + df['theme'] + \" \" + df['concept'] + \" \" + df['franchise'] + \" \" + df['platform']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframe has 37026 entries now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the developer, genre, theme, and concept features by examining the distribution using Bar plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bar_Plot(df, x, y, title, x_title, y_title):\n",
    "    \"\"\"Function which returns a bar plot of a feature.\"\"\"    \n",
    "    # Plot\n",
    "    bar = px.bar(df, x = x,\n",
    "                 y = y, orientation = 'h',\n",
    "                 color = y, color_discrete_sequence = px.colors.qualitative.Pastel\n",
    "                )\n",
    "    \n",
    "    bar.update_xaxes(linewidth = 1, linecolor = 'black', \n",
    "                     gridcolor = 'LightPink',  \n",
    "                     ticks = \"outside\", tickwidth = 2,\n",
    "                     tickcolor = 'black', ticklen = 12,\n",
    "                     title = x_title, title_font = dict(size = 22),\n",
    "                    ) \n",
    "    bar.update_yaxes(linewidth = 1, linecolor = 'black', \n",
    "                     gridcolor = 'LightPink', ticks = \"outside\",\n",
    "                     tickwidth = 2, tickcolor = 'black',\n",
    "                     ticklen = 12, title = y_title,\n",
    "                     title_font = dict(size = 22),\n",
    "                    )\n",
    "    \n",
    "    \n",
    "    bar.update_layout(\n",
    "        title = title,\n",
    "        title_font = dict(size = 26),\n",
    "        font = dict(size = 14),\n",
    "        legend = dict(\n",
    "            x = 1,\n",
    "            y = 1,\n",
    "            traceorder = \"normal\",\n",
    "            font = dict(\n",
    "                family = \"sans-serif\",\n",
    "                size = 18,\n",
    "                color = \"black\"\n",
    "            ),\n",
    "            bgcolor = \"#f7f7f7\",\n",
    "            bordercolor = \"#f7f7f7\",\n",
    "            borderwidth = 1\n",
    "        ),\n",
    "        plot_bgcolor = \"#f7f7f7\", paper_bgcolor = \"#f7f7f7\",\n",
    "        width = 1000, height = 600, \n",
    "        hoverlabel = dict(\n",
    "            font_size = 24, \n",
    "            font_family = \"Rockwell\")\n",
    "    )\n",
    "\n",
    "    return bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of games do not have a developer listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of developers.\n",
    "Bar_Plot(df = df, x = df['developer'].value_counts().values[0:10],\n",
    "         y = df['developer'].value_counts().index[0:10], title = 'Distribution of Developers',\n",
    "         x_title = 'Count', y_title = 'Developer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most video games are in the adventure genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of genres.\n",
    "Bar_Plot(df = df, x = df['genre'].value_counts().values[0:10],\n",
    "         y = df['genre'].value_counts().index[0:10], title = 'Distribution of Genres',\n",
    "         x_title = 'Count', y_title = 'Genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of games have a fantasy theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of themes.\n",
    "Bar_Plot(df = df, x = df['theme'].value_counts().values[0:10],\n",
    "         y = df['theme'].value_counts().index[0:10], title = 'Distribution of Themes',\n",
    "         x_title = 'Count', y_title = 'Theme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of games have single word titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of concepts.\n",
    "Bar_Plot(df = df, x = df['concept'].value_counts().values[0:10],\n",
    "         y = df['concept'].value_counts().index[0:10], title = 'Distribution of Concepts',\n",
    "         x_title = 'Count', y_title = 'Concept')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll explore those previous features with word clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_cloud(df):\n",
    "    \"\"\"Function to create and plot a worcloud\"\"\"\n",
    "\n",
    "    ## Collect all strings \n",
    "    tmp_contents = ''\n",
    "    for x in df:\n",
    "        tmp_contents += x\n",
    "    \n",
    "    # The regex expression is used to eliminate all non english letters\n",
    "    regex_expression = r\"[a-zA-Z]+\"\n",
    "    \n",
    "    # Word Cloud\n",
    "    wc = WordCloud(width = 2500, height = 1000, max_words = 10000,\n",
    "                      relative_scaling = 0, background_color = 'black', contour_color = \"black\",\n",
    "                      regexp = regex_expression, random_state = 2, colormap = 'rainbow',\n",
    "                      collocations = False,\n",
    "             ).generate(tmp_contents)\n",
    "    \n",
    "    # Set figure size\n",
    "    plt.figure(figsize = (20, 15))\n",
    "    \n",
    "    # Display image\n",
    "    plt.imshow(wc) \n",
    "    \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud of total contents.\n",
    "plot_word_cloud(df = df['total_contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud of genres.\n",
    "plot_word_cloud(df = df['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud of themes.\n",
    "plot_word_cloud(df = df['theme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud of concepts.\n",
    "plot_word_cloud(df = df['concept'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Recommendation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF is a numerical statistic that shows the relevance of keywords to\n",
    "some specific documents or it can be said that, it provides those keywords, using which some specific documents can be identified or categorized [1]. TF-IDF is a combination of two different words i.e. Term\n",
    "Frequency and Inverse Document Frequency. \n",
    "\n",
    "Term Frequency (TF) is used to measure that how many times a term is present in a document as presented in Equation (1).\n",
    "\n",
    "$TF = \\frac{Term}{Total Words}$ (Equation 1)\n",
    "\n",
    "Inverse document frequency (IDF) assigns lower weight to frequent words and assigns greater weight for the words that are infrequent as presented in Equation (2).\n",
    "\n",
    "$IDF = log_e(\\frac{Total Documents}{Document Frequency})$ (Equation 2)\n",
    "\n",
    "TF-IDF is the multiplication of the term frequency and inverse document frequency as presented in Equation (3).\n",
    "\n",
    "\n",
    "$TF-DF = TF*IDF$ (Equation 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll be using the tf-idf vectorizer from sci-kit learn to transform our dataframe. Main parameters of interest are the max features and stop word list.\n",
    "\n",
    "* Max number of features - selects the top n features with the highest td-idf scores. (~1250 in our cases, to have a balance between running time and recommendation fidelity)\n",
    "* Stop words list - words that will be eliminated from tf-idf calculations. (eliminate words which have nothing to do with video game content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_vectorizer(df, max_features):\n",
    "    \"Function to return the td-idf matrix and parameters.\"\n",
    "    # Stop words\n",
    "    stop_words_list = ['000', '007', '07th', '09',\n",
    "                       '10', '100', '101', '1047', \n",
    "                        '11', '12', '120', '13', '130cm',\n",
    "                       '13am', '13th', '14', '141', '15',\n",
    "                       '1500', '16', '17', '18', '180', '1939',\n",
    "                       '1942', '1960s', '1980s', '1990s',\n",
    "                       '1995', '1996', '1997', '1998', '1999',\n",
    "                       '19th', '1c', '1soft', '1st', '20', '2000',\n",
    "                       '2001','2002', '2003', '2004', '2005', '2006',\n",
    "                       '2007', '2008', '2009', '2010', '2011', '2012',\n",
    "                       '2013', '2014', '2015', '2016', '2017', '2018',\n",
    "                       '2019', '2020', '2020venture',  '20th', '21',\n",
    "                       '21st', '22', '221b', '227',  '22nd', '23rd', '24',\n",
    "                       '258', '285',  '2darray',  '2nd', '2x2',\n",
    "                       '2xl', '3000', '3000ad', '32x', '343',\n",
    "                       '35', '358', '360', '369', '3a', '3d6',\n",
    "                       '3ds', '3g', '3lv', '3rd', '3x3', '40',\n",
    "                       '400', '44', '45', '46', '4a', '4bit', \n",
    "                       '4head', '4j', '4sdk', '4x', '50th',\n",
    "                       '51', '5200', '562', '5656', '59',  '5d', '5pb',\n",
    "                       '5th', '60', '6010', '64', '6e6e6e', '76', '777',\n",
    "                       '777next', '7dfps', '7th', '800', '82', '8888888',\n",
    "                       '88mm', '8floor', '8monkey', '8th', '935', '98',\n",
    "                       '98demake', '9heads', '9th', 'a2a', 'a2z',\n",
    "                       '0verflow', '10kbit', '10tacle', '10tons', '2049er', '20xx',\n",
    "                       '22cans', '2awesome', '2bad', '2d', '2dengine', '2dogs', '2k',\n",
    "                       '34bigthings', '3d', '3dclouds', '3division', '3do', '3drunkmen',\n",
    "                       '3rdeye', '3vision', '3vr', '49ers', '49games', '4d', '4fufelz',\n",
    "                       '4gency', '5bit', 'aaa', 'aaaaaaaaaaaaaaaaaaaaaaaaa', 'ab',\n",
    "                       'e10', 'e3', 'e404', 'pax',\n",
    "                       'achievements', 'com', 'comachievements', 'companynameintitle',\n",
    "                       'crowdfunded', 'declarativetitle', 'digitaldistribution',\n",
    "                       'e32005', 'e32007', 'e32008', 'e32009', 'e32010',\n",
    "                       'e32011', 'e32012', 'e32013', 'e32014', 'e32015',\n",
    "                       'e32016', 'e32017', 'e32018', 'e32019', 'e32020',\n",
    "                       'easyanticheat', 'epicgamesstore', 'gametitlesthatarealsoquestions', 'gog',\n",
    "                       'humblebundle', 'kickstarterfunded', 'licensedgame', 'onlive',\n",
    "                       'paxeast2005', 'paxeast2007', 'paxeast2008', 'paxeast2009',\n",
    "                       'paxeast2010', 'paxeast2011', 'paxeast2012', 'paxeast2013',\n",
    "                       'paxeast2014', 'paxeast2015', 'paxeast2016', 'paxeast2017',\n",
    "                       'paxeast2018', 'paxeast2019', 'paxeast2020',\n",
    "                       'paxprime', 'paxprime2005', 'paxprime2007', 'paxprime2008',\n",
    "                       'paxprime2009', 'paxprime2010', 'paxprime2011', 'paxprime2012', 'paxprime2013',\n",
    "                       'paxprime2014', 'paxprime2015', 'paxprime2016', 'paxprime2017', 'paxprime2018',\n",
    "                       'paxprime2019', 'paxprime2020', 'paxsouth2005', 'paxsouth2007', 'paxsouth2008',\n",
    "                       'paxsouth2009', 'paxsouth2010', 'paxsouth2011', 'paxsouth2012', 'paxsouth2013',\n",
    "                       'paxsouth2014', 'paxsouth2015', 'paxsouth2016', 'paxsouth2017', 'paxsouth2018',\n",
    "                       'paxsouth2019', 'paxsouth2020',\n",
    "                       'paxwest2005', 'paxwest2007', 'paxwest2008', 'paxwest2009',\n",
    "                       'paxwest2010', 'paxwest2011', 'paxwest2012', 'paxwest2013',\n",
    "                       'paxwest2014', 'paxwest2015', 'paxwest2016', 'paxwest2017',\n",
    "                       'paxwest2018', 'paxwest2019', 'paxwest2020', 'playstation',\n",
    "                       'playstationplus', 'playstationtrophies', 'realphotosoncoverart',\n",
    "                       'secretachievements', 'smartdelivery', 'steam', 'steamapplearcade',\n",
    "                       'steamcloud', 'steamgreenlight', 'steamremoteplaytogether', 'steamtradingcards',\n",
    "                       'steamturnnotifications', 'threewordgametitlewithconjunctionorpreposition',\n",
    "                       'trophies', 'valveindexsupport', 'xboxonexenhanced', 'xboxplayanywhere']\n",
    "    \n",
    "    tf = TfidfVectorizer(stop_words = stop_words_list, max_features = max_features)\n",
    "    \n",
    "    # Fit and Transform using TD-IDF Vectorizer\n",
    "    tfidf_matrix = tf.fit_transform(df['total_contents'].values.astype('U'))\n",
    "    \n",
    "    # Observe the frequency of each word in the matrix\n",
    "    df_tfidf = pd.DataFrame(tfidf_matrix.todense(), columns = tf.get_feature_names())\n",
    "    \n",
    "    return df_tfidf, tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot the distribution of tf-idf and word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF distribution.\n",
    "## Initalize TF-IDF vectors\n",
    "tf_idf_predictions, tf = tf_idf_vectorizer(df = df, max_features = 1250)\n",
    "tmp_features = tf.get_feature_names()\n",
    "\n",
    "## Create dataframe\n",
    "data =  {'Words': tmp_features,\n",
    "         'TF-IDF': tf.idf_\n",
    "        }\n",
    "\n",
    "tmp_df = pd.DataFrame(data = data)\n",
    "\n",
    "sorted_df = tmp_df.sort_values(by = 'TF-IDF', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF distribution.\n",
    "## Bar Plot\n",
    "Bar_Plot(df = sorted_df[0:20], x = 'TF-IDF',\n",
    "         y = 'Words', title = 'Distribution of TF-IDF Words',\n",
    "         x_title = 'TF-IDF', y_title = 'Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud\n",
    "## Create word frequencies\n",
    "tmp_dict = dict(zip(sorted_df['Words'].values, sorted_df['TF-IDF'].values))\n",
    "\n",
    "## The regex expression is used to eliminate all non english letters\n",
    "regex_expression = r\"[a-zA-Z]+\"\n",
    "\n",
    "## Word Cloud\n",
    "wc_freq = WordCloud(width = 2500, height = 1000, max_words = 10000,\n",
    "                  relative_scaling = 0, background_color = 'black', contour_color = \"black\",\n",
    "                  regexp = regex_expression, random_state = 2, colormap = 'rainbow',\n",
    "                  collocations = False,\n",
    "         ).generate_from_frequencies(tmp_dict)\n",
    "\n",
    "## Set figure size\n",
    "plt.figure(figsize = (20, 15))\n",
    "\n",
    "## Display image\n",
    "plt.imshow(wc_freq) \n",
    "\n",
    "## No axis details\n",
    "plt.axis(\"off\");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Analysis\n",
    "\n",
    "Algorithms were selected based on their application to the problem of Information Retrieval - since our problem involves content descriptions and not the use of user collaborative filtering to provide recommendations. Such methods include identifying similarity pairs between points, thus the use of cosine similarity and k-nearest neighbors is an adequate choice. \n",
    "\n",
    "The algorithms will be critiqued based on\n",
    "\n",
    "(1) Effective running time (how long does it take to run). It's imperative as running time will be a crucial metric in application deployment as the platform has constraints on how long the application can take for calculations.\n",
    "\n",
    "(2) Relevance -  my opinion on if the recommendations are viable. It's important that the recommendations have a consistent relevancy towards the user's inputted games. There are six test cases, which will be judging this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine Similarity\n",
    "\n",
    "https://www.sciencedirect.com/topics/computer-science/cosine-similarity [2]\n",
    "\n",
    "Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction.\n",
    "\n",
    "$ sim(x,y) = \\frac{xy}{|x||y|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_game_recommendations(df, game_1, game_2, game_3, game_4, game_5):\n",
    "    # Recording elapsed time\n",
    "    start = time.time()\n",
    "    \n",
    "    # Dataframe\n",
    "    df = df\n",
    "\n",
    "    # Input IDS\n",
    "    ## Checks for the datatype of the inputted games either None or the title of the game\n",
    "    input_ids = []\n",
    "    for x in game_1, game_2, game_3, game_4, game_5:\n",
    "        if x != None:\n",
    "            input_ids.append(df[df['name'] == x].index[0])\n",
    "\n",
    "    # Iterate through each game selected and append the game's description into a list  \n",
    "    game_text_list = []\n",
    "    for x in game_1, game_2, game_3, game_4, game_5:\n",
    "        if (x != None) & (df['name'].isin([x]).any() == True):\n",
    "                          game_text_list.append(((df[df['name'] == x]['total_contents'].values)))\n",
    "        elif (x != None) & (df['name'].isin([x]).any() == False):\n",
    "                            return( 'Game inputted is not in dataset')\n",
    "    \n",
    "    # Concatenate the strings\n",
    "    game_text_strings = ''\n",
    "    for x in game_text_list:\n",
    "        game_text_strings += x \n",
    "    \n",
    "    # Insert a new row with the concatenated string\n",
    "    df = df.append({'name' : 'User Input' , 'total_contents' : game_text_strings[0]} , ignore_index = True)\n",
    "   \n",
    "    # TF-IDF Vectorizer\n",
    "    tf_idf_predictions, tf = tf_idf_vectorizer(df = df, max_features = 1250)\n",
    "\n",
    "    # Cosim Similarity\n",
    "    cosine_sim = cosine_similarity(tf_idf_predictions)\n",
    "\n",
    "    ## Labeling the name and genre of the results in the cosine similarity \n",
    "    titles = df[['name', 'genre']]\n",
    "    indices = pd.Series(df.index, index = df['name'])\n",
    "    \n",
    "    ## Creation of the cosine similarity list\n",
    "    idx = indices['User Input']\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:16]\n",
    "    game_indices = [i[0] for i in sim_scores if i[0] not in input_ids]\n",
    "    \n",
    "    # After, the game recommendations have completed, drop the entry used to concatenate the strings.\n",
    "    df.drop(df.tail(1).index,inplace = True)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(f'Time Elapsed: {end - start} seconds ')\n",
    "    \n",
    "    return titles.iloc[game_indices][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adequate results from the test cases, but there is an issue with test case #2, as the amount of batman games is overwhelming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Action Platformer and 1 Action Adventure \n",
    "test_case_1 = cs_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'Batman: Arkham City', game_3 = None,\n",
    "                     game_4 = None, game_5 = None)\n",
    "\n",
    "test_case_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Action Platformers and 1 ActionAdventure \n",
    "test_case_2 = cs_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'Castlevania', game_3 = 'Fumiko!',\n",
    "                     game_4 = '99 Levels To Hell', game_5 = 'Batman: Arkham Asylum')\n",
    "\n",
    "test_case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5 Action Platformers \n",
    "test_case_3 = cs_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'A.R.E.S. Extinction Agenda EX', game_3 = 'Fumiko!',\n",
    "                     game_4 = '99 Levels To Hell', game_5 = 'Zack Zero')\n",
    "\n",
    "test_case_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 MMORGPS\n",
    "test_case_4 = cs_game_recommendations(df = df, game_1 = 'Albion Online',\n",
    "                     game_2 = 'ArcheAge', game_3 = 'World of Warcraft',\n",
    "                     game_4 = 'City of Heroes', game_5 = 'City of Villains')\n",
    "\n",
    "test_case_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Action Platformers and 1 ActionAdventure\n",
    "test_case_5 = cs_game_recommendations(df = df, game_1 = '8-Bit Hordes',\n",
    "                     game_2 = '8-Bit Invaders!', game_3 = '9th Company: Roots of Terror',\n",
    "                     game_4 = 'A Game of Thrones: Genesis', game_5 = 'Batman: Arkham Asylum')\n",
    "\n",
    "test_case_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Shooters\n",
    "test_case_6 = cs_game_recommendations(df = df, game_1 = '8bit Killer',\n",
    "                     game_2 = 'Alien Swarm', game_3 = 'Doom VFR',\n",
    "                     game_4 = 'Earth Defense Force 5', game_5 = 'Fortnite')\n",
    "\n",
    "test_case_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors\n",
    "\n",
    "The  K-Nearest  Neighbor  (KNN)  is  one  of  the  simplest  lazy  machine  learning  algorithms. Algorithm  objective  is  to  classify  objects  into  one  of  the  predefined  classes  of  a  sample  group  that  was  created  by  machine  learning. The algorithm does not require the use of training data to perform classification, training data can be used during the testing phase. KNN is based on finding the most similar objects (documents) from sample groups about a mutal distance metric [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_game_recommendations(df, game_1, game_2, game_3, game_4, game_5):\n",
    "    # Recording elapsed time\n",
    "    start = time.time()\n",
    "    \n",
    "    # Dataframe\n",
    "    df = df\n",
    "\n",
    "    # Iterate through each game selected and append the game's description into a list  \n",
    "    game_text_list = []\n",
    "    for x in game_1, game_2, game_3, game_4, game_5:\n",
    "        if (x != None) & (df['name'].isin([x]).any() == True):\n",
    "                          game_text_list.append(((df[df['name'] == x]['total_contents'].values)))\n",
    "        elif (x != None) & (df['name'].isin([x]).any() == False):\n",
    "                            return( 'Game inputted is not in dataset')\n",
    "    \n",
    "    # Concatenate the strings\n",
    "    game_text_strings = ''\n",
    "    for x in game_text_list:\n",
    "        game_text_strings += x \n",
    "    \n",
    "    # TD-IDF Vectorizer\n",
    "    tf_idf_inputs, tf = tf_idf_vectorizer(df = df, max_features = 1250)\n",
    "    \n",
    "    # Nearest Neighbors\n",
    "    nn = NearestNeighbors(n_neighbors = 15, algorithm='ball_tree', metric = 'minkowski')\n",
    "    nn.fit(tf_idf_inputs)\n",
    "    \n",
    "    # Transforming the predictions\n",
    "    tf_idf_predictions = tf.transform([str(game_text_strings)])\n",
    "    results = nn.kneighbors(tf_idf_predictions.todense())\n",
    "    \n",
    "    # Input IDS\n",
    "    ## Checks for the datatype of the inputted games either None or the title of the game\n",
    "    input_ids = []\n",
    "    for x in game_1, game_2, game_3, game_4, game_5:\n",
    "        if x != None:\n",
    "            input_ids.append(df[df['name'] == x].index[0])\n",
    "    \n",
    "    # Recommended Game ID's\n",
    "    ## Checks to see if any of the recommended titles are not the inputted games - do not get recommended games you selected\n",
    "    tmp_ids = [x for x in results[1][0]]\n",
    "    top_10_ids = []\n",
    "    for x in tmp_ids:\n",
    "        if x not in input_ids:\n",
    "            top_10_ids.append(x)\n",
    "    \n",
    "    # The TOP 10 games selected\n",
    "    ## Returns the title of recommendedd games\n",
    "    top_10_games_list = []\n",
    "    for x in top_10_ids:\n",
    "        top_10_games_list.append(df[df.index == x]['name'].values[0])\n",
    "    \n",
    "    \n",
    "    # Labeling the name and genre of the top 10_games\n",
    "    titles = df[['name', 'genre']]\n",
    "    indices = pd.Series(df.index, index = df['name'])\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'Time Elapsed: {end - start} seconds ')\n",
    "    \n",
    "    return titles.iloc[top_10_ids][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adequate results from the test cases, but there is an issue with test case #2, as the amount of batman games is overwhelming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Action Platformer and 1 Action Adventure \n",
    "test_case_1 = knn_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'Batman: Arkham City', game_3 = None,\n",
    "                     game_4 = None, game_5 = None)\n",
    "\n",
    "test_case_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Action Platformers and 1 ActionAdventure \n",
    "test_case_2 = knn_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'Castlevania', game_3 = 'Fumiko!',\n",
    "                     game_4 = '99 Levels To Hell', game_5 = 'Batman: Arkham Asylum')\n",
    "\n",
    "test_case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5 Action Platformers \n",
    "test_case_3 = knn_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'A.R.E.S. Extinction Agenda EX', game_3 = 'Fumiko!',\n",
    "                     game_4 = '99 Levels To Hell', game_5 = 'Zack Zero')\n",
    "\n",
    "test_case_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 MMORGPS\n",
    "test_case_4 = knn_game_recommendations(df = df, game_1 = 'Albion Online',\n",
    "                     game_2 = 'ArcheAge', game_3 = 'World of Warcraft',\n",
    "                     game_4 = 'City of Heroes', game_5 = 'City of Villains')\n",
    "\n",
    "test_case_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Action Platformers and 1 ActionAdventure\n",
    "test_case_5 = knn_game_recommendations(df = df, game_1 = '8-Bit Hordes',\n",
    "                     game_2 = '8-Bit Invaders!', game_3 = '9th Company: Roots of Terror',\n",
    "                     game_4 = 'A Game of Thrones: Genesis', game_5 = 'Batman: Arkham Asylum')\n",
    "\n",
    "test_case_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Shooters\n",
    "test_case_6 = knn_game_recommendations(df = df, game_1 = '8bit Killer',\n",
    "                     game_2 = 'Alien Swarm', game_3 = 'Doom VFR',\n",
    "                     game_4 = 'Earth Defense Force 5', game_5 = 'Fortnite')\n",
    "\n",
    "test_case_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular value decomposition takes a rectangular matrix of gene expression data (defined as A, where A is a n x p matrix) in which the n rows represents the genes, and the p columns represents the experimental conditions [4].\n",
    "\n",
    "The SVD theorem states:\n",
    "\n",
    "$ A_{nxp} = U_{nxn}S_{nxp}V^T_{pxp} $ (Equation 1)\n",
    "\n",
    "$ U^TU = I_{nxn}$\n",
    "\n",
    "$ V^TV = I_{pxp}$\n",
    "\n",
    "SVD is useful as a dimensional reduction technique - reducing the number of features but capturing the variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the relationship between the number of components and experience demonstrated that ~450 number of components is sufficient to represent ~85% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "## SVD\n",
    "tf_idf_predictions, tf = tf_idf_vectorizer(df = df, max_features = 1250)\n",
    "\n",
    "SVD_components_variance = []\n",
    "Number_of_components = []\n",
    "for x in range(0, 800, 50):\n",
    "    tsv = TruncatedSVD( n_components = x, algorithm = 'randomized', n_iter = 5).fit(tf_idf_predictions)\n",
    "    tsv_variance_components = tsv.explained_variance_ratio_.sum()\n",
    "    Number_of_components.append(x)\n",
    "    SVD_components_variance.append(tsv_variance_components)\n",
    "\n",
    "## Plot Parameters\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(Number_of_components, SVD_components_variance,  '-o')\n",
    "plt.xlabel('Number of Components', fontsize = 24)\n",
    "plt.xticks(fontsize = 18)\n",
    "plt.yticks([x / 10.0 for x in range(0, 10, 1)], fontsize = 18)\n",
    "plt.ylabel('Variance (%)', fontsize = 24) \n",
    "plt.title('SVD Variance', fontsize = 24)\n",
    "\n",
    "## Annotate plot \n",
    "plt.text(200, SVD_components_variance[9] + 0.015,\n",
    "         '85% cutoff', size = 20, color = 'red', weight = 'semibold')\n",
    "\n",
    "plt.hlines(y = 0.85, color = 'red', linestyle = '-', xmin = 0.0, xmax = 450)\n",
    "plt.vlines(x = 450, color = 'red', linestyle = '-', ymin = 0.0, ymax = 0.85)\n",
    "\n",
    "plt.text(440, SVD_components_variance[9] + 0.015,\n",
    "         str(round(SVD_components_variance[9], 3)), size = 20, color = 'blue', weight = 'semibold')\n",
    "\n",
    "plt.text(455, 0.4,\n",
    "         '450 components are sufficient', size = 20, color = 'red', weight = 'semibold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine Similarity + SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_svd_game_recommendations(df, game_1, game_2, game_3, game_4, game_5):\n",
    "    # Recording elapsed time\n",
    "    start = time.time()\n",
    "    \n",
    "    # Dataframe\n",
    "    df = df\n",
    "\n",
    "    # Input IDS\n",
    "    ## Checks for the datatype of the inputted games either None or the title of the game\n",
    "    input_ids = []\n",
    "    for x in game_1, game_2, game_3, game_4, game_5:\n",
    "        if x != None:\n",
    "            input_ids.append(df[df['name'] == x].index[0])\n",
    "\n",
    "    # Iterate through each game selected and append the game's description into a list  \n",
    "    game_text_list = []\n",
    "    for x in game_1, game_2, game_3, game_4, game_5:\n",
    "        if (x != None) & (df['name'].isin([x]).any() == True):\n",
    "                          game_text_list.append(((df[df['name'] == x]['total_contents'].values)))\n",
    "        elif (x != None) & (df['name'].isin([x]).any() == False):\n",
    "                            return( 'Game inputted is not in dataset')\n",
    "    \n",
    "    # Concatenate the strings\n",
    "    game_text_strings = ''\n",
    "    for x in game_text_list:\n",
    "        game_text_strings += x \n",
    "    \n",
    "    # Insert a new row with the concatenated string\n",
    "    df = df.append({'name' : 'User Input', 'total_contents' : game_text_strings[0]} , ignore_index = True)\n",
    "   \n",
    "    # TD-IDF Vectorizer\n",
    "    tf_idf_predictions, tf = tf_idf_vectorizer(df = df, max_features = 1250)\n",
    "    \n",
    "    # SVD\n",
    "    tsv = TruncatedSVD(n_components = 450, algorithm = 'randomized', n_iter = 5, random_state = 7)\n",
    "\n",
    "    svd_predictions = tsv.fit_transform(tf_idf_predictions)\n",
    "    \n",
    "    # Cosim Similarity\n",
    "    cosine_sim = cosine_similarity(svd_predictions)\n",
    "    \n",
    "    ## Labeling the name and genre of the results in the cosine similarity \n",
    "    titles = df[['name', 'genre']]\n",
    "    indices = pd.Series(df.index, index = df['name'])\n",
    "    \n",
    "    ## Creation of the cosine similarity list\n",
    "    idx = indices['User Input']\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:16]\n",
    "    game_indices = [i[0] for i in sim_scores if i[0] not in input_ids]\n",
    "    \n",
    "    # After, the game recommendations have completed, drop the entry used to concatenate the strings.\n",
    "    df.drop(df.tail(1).index,inplace = True)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(f'Time Elapsed: {end - start} seconds ')\n",
    "    \n",
    "    return titles.iloc[game_indices][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed better on test case #2, but running time will be an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Action Platformer and 1 Action Adventure \n",
    "test_case_1 = cs_svd_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'Batman: Arkham City', game_3 = None,\n",
    "                     game_4 = None, game_5 = None)\n",
    "\n",
    "test_case_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Action Platformers and 1 ActionAdventure \n",
    "test_case_2 = cs_svd_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'Castlevania', game_3 = 'Fumiko!',\n",
    "                     game_4 = '99 Levels To Hell', game_5 = 'Batman: Arkham Asylum')\n",
    "\n",
    "test_case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5 Action Platformers \n",
    "test_case_3 = cs_svd_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'A.R.E.S. Extinction Agenda EX', game_3 = 'Fumiko!',\n",
    "                     game_4 = '99 Levels To Hell', game_5 = 'Zack Zero')\n",
    "\n",
    "test_case_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 MMORGPS\n",
    "test_case_4 = cs_svd_game_recommendations(df = df, game_1 = 'Albion Online',\n",
    "                     game_2 = 'ArcheAge', game_3 = 'World of Warcraft',\n",
    "                     game_4 = 'City of Heroes', game_5 = 'City of Villains')\n",
    "\n",
    "test_case_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Action Platformers and 1 ActionAdventure\n",
    "test_case_5 = cs_svd_game_recommendations(df = df, game_1 = '8-Bit Hordes',\n",
    "                     game_2 = '8-Bit Invaders!', game_3 = '9th Company: Roots of Terror',\n",
    "                     game_4 = 'A Game of Thrones: Genesis', game_5 = 'Batman: Arkham Asylum')\n",
    "\n",
    "test_case_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Shooters\n",
    "test_case_6 = cs_svd_game_recommendations(df = df, game_1 = '8bit Killer',\n",
    "                     game_2 = 'Alien Swarm', game_3 = 'Doom VFR',\n",
    "                     game_4 = 'Earth Defense Force 5', game_5 = 'Fortnite')\n",
    "\n",
    "test_case_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors + SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_svd_game_recommendations(df, game_1, game_2, game_3, game_4, game_5):\n",
    "    # Recording elapsed time\n",
    "    start = time.time()\n",
    "    \n",
    "    # Dataframe\n",
    "    df = df\n",
    "\n",
    "    # Iterate through each game selected and append the game's description into a list  \n",
    "    game_text_list = []\n",
    "    for x in game_1, game_2, game_3, game_4, game_5:\n",
    "        if (x != None) & (df['name'].isin([x]).any() == True):\n",
    "                          game_text_list.append(((df[df['name'] == x]['total_contents'].values)))\n",
    "        elif (x != None) & (df['name'].isin([x]).any() == False):\n",
    "                            return( 'Game inputted is not in dataset')\n",
    "    \n",
    "    # Concatenate the strings\n",
    "    game_text_strings = ''\n",
    "    for x in game_text_list:\n",
    "        game_text_strings += x \n",
    "    \n",
    "    # TD-IDF Vectorizer\n",
    "    #tf_idf_inputs, tf = tf_idf_vectorizer(df = df, max_features = 3500)\n",
    "    tf_idf_inputs, tf = tf_idf_vectorizer(df = df, max_features = 1250)\n",
    "    \n",
    "    # SVD\n",
    "    tsv = TruncatedSVD(n_components = 450, algorithm='randomized',n_iter=5, random_state = 7)\n",
    "    svd_inputs = tsv.fit_transform(tf_idf_inputs)\n",
    "    \n",
    "    # Nearest Neighbors\n",
    "    nn = NearestNeighbors(n_neighbors = 15, algorithm='ball_tree', metric = 'minkowski')\n",
    "    nn.fit(svd_inputs)\n",
    "    \n",
    "    # Transforming the predictions\n",
    "    tf_idf_predictions = tf.transform([str(game_text_strings)])\n",
    "    \n",
    "    svd_predictions = tsv.transform(tf_idf_predictions)\n",
    "    results = nn.kneighbors(svd_predictions)\n",
    "    \n",
    "    # Input IDS\n",
    "    ## Checks for the datatype of the inputted games either None or the title of the game\n",
    "    input_ids = []\n",
    "    for x in game_1, game_2, game_3, game_4, game_5:\n",
    "        if x != None:\n",
    "            input_ids.append(df[df['name'] == x].index[0])\n",
    "    \n",
    "    # Recommended Game ID's\n",
    "    ## Checks to see if any of the recommended titles are not the inputted games - do not get recommended games you selected\n",
    "    tmp_ids = [x for x in results[1][0]]\n",
    "    top_10_ids = []\n",
    "    for x in tmp_ids:\n",
    "        if x not in input_ids:\n",
    "            top_10_ids.append(x)\n",
    "    \n",
    "    # The TOP 10 games selected\n",
    "    ## Returns the title of recommendedd games\n",
    "    top_10_games_list = []\n",
    "    for x in top_10_ids:\n",
    "        top_10_games_list.append(df[df.index == x]['name'].values[0])\n",
    "    \n",
    "    \n",
    "    # Labeling the name and genre of the top 10_games\n",
    "    titles = df[['name', 'genre']]\n",
    "    indices = pd.Series(df.index, index = df['name'])\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'Time Elapsed: {end - start} seconds ')\n",
    "    \n",
    "    return titles.iloc[top_10_ids][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed better than its previous iteration but not as strong as cs + svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Action Platformer and 1 Action Adventure \n",
    "test_case_1 = knn_svd_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'Batman: Arkham City', game_3 = None,\n",
    "                     game_4 = None, game_5 = None)\n",
    "\n",
    "test_case_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Action Platformers and 1 ActionAdventure \n",
    "test_case_2 = knn_svd_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'Castlevania', game_3 = 'Fumiko!',\n",
    "                     game_4 = '99 Levels To Hell', game_5 = 'Batman: Arkham Asylum')\n",
    "\n",
    "test_case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5 Action Platformers \n",
    "test_case_3 = knn_svd_game_recommendations(df = df, game_1 = '30XX',\n",
    "                     game_2 = 'A.R.E.S. Extinction Agenda EX', game_3 = 'Fumiko!',\n",
    "                     game_4 = '99 Levels To Hell', game_5 = 'Zack Zero')\n",
    "\n",
    "test_case_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 MMORGPS\n",
    "test_case_4 = knn_svd_game_recommendations(df = df, game_1 = 'Albion Online',\n",
    "                     game_2 = 'ArcheAge', game_3 = 'World of Warcraft',\n",
    "                     game_4 = 'City of Heroes', game_5 = 'City of Villains')\n",
    "\n",
    "test_case_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Action Platformers and 1 ActionAdventure\n",
    "test_case_5 = knn_svd_game_recommendations(df = df, game_1 = '8-Bit Hordes',\n",
    "                     game_2 = '8-Bit Invaders!', game_3 = '9th Company: Roots of Terror',\n",
    "                     game_4 = 'A Game of Thrones: Genesis', game_5 = 'Batman: Arkham Asylum')\n",
    "\n",
    "test_case_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Shooters\n",
    "test_case_6 = knn_svd_game_recommendations(df = df, game_1 = '8bit Killer',\n",
    "                     game_2 = 'Alien Swarm', game_3 = 'Doom VFR',\n",
    "                     game_4 = 'Earth Defense Force 5', game_5 = 'Fortnite')\n",
    "\n",
    "test_case_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of performance, CS + SVD > KNN + SVD > CS = KNN. However, running time is an issue for cosine similarity methods, thus moving forward in deploying our application, KNN will be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values  =  [['Cosine Similarity',\n",
    "           'Cosine Similarity + SVD',\n",
    "           'K-Nearest Neighbors',\n",
    "           'K-Nearest Neighbors + SVD',\n",
    "          ], #1st col\n",
    " \n",
    "          ['18.409',\n",
    "           '26.427',\n",
    "           '4.094',\n",
    "           '12.552',\n",
    "\n",
    "          ], #2nd col\n",
    "          \n",
    "          ['3rd',\n",
    "           '1st',\n",
    "            '3rd',\n",
    "           '2nd',\n",
    "          ], ]\n",
    "\n",
    "\n",
    "fig  =  go.Figure(data = [go.Table(\n",
    "    columnorder  =  [1,2, 3, 4, 5, 6, 7],\n",
    "    columnwidth  =  [150, 100, 100],\n",
    "    header  =  dict(\n",
    "        values  =  [['Method'],\n",
    "                    ['Elapsed Time (seconds)'],\n",
    "                    ['Relevance']],\n",
    "        line_color = 'darkslategray',\n",
    "        fill_color = '#90ee90',\n",
    "        align = ['left','center'],\n",
    "        font = dict(color = 'Light Gray', size = 24),\n",
    "        height = 40\n",
    "    ),\n",
    "    cells = dict(\n",
    "        values = values,\n",
    "        line_color = 'darkslategray',\n",
    "        fill = dict(color = ['#ffb6c1', 'White']),\n",
    "        font_size =  16,\n",
    "        height = 40)\n",
    ")\n",
    "                         ]\n",
    "                 )\n",
    "#width  =  4600, height  =  950,\n",
    "fig.update_layout(width  =  900, height  =  500,\n",
    "                  title  =  'Table 1: Algorithms for Game Recommendations',\n",
    "                  title_font  =  {'size': 24})\n",
    "fig.update_xaxes(automargin = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III: PostgreSQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deploying our application, our data needs to be stored in a safe and reliable database. \n",
    "\n",
    "(1) Store our CSV into a PostgreSQL database, which is saved on the heroku platform.\n",
    "\n",
    "(2) Reliably pull our data from (1) into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data entries form dataframe for maximum performance (SQL database only supports up to 10k entries)\n",
    "# Drop empty developer entries\n",
    "df = df.drop(df.loc[df['developer'] == ''].index).reset_index(drop = True)\n",
    "\n",
    "# Drop entries without a franchise listed\n",
    "df = df.drop(df.loc[df['franchise'] != ''].index).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to SQL database\n",
    "DATABASE_URL = 'Heroku URL'\n",
    "engine = create_engine(DATABASE_URL)\n",
    "df.to_sql('video_games', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in SQL\n",
    "DATABASE_URL = 'Heroku URL'\n",
    "conn = psycopg2.connect(DATABASE_URL, sslmode = 'require')\n",
    "df = pd.read_sql('select * from video_games', con = conn, index_col = 'index') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on the deployment of the application, look into the app_deployment folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] S. Qaiser and R. Ali, \"Text Mining: Use of TF-IDF to Examine the Relevance of Words to Documents\", International Journal of Computer Applications, vol. 181, no. 1, pp. 25-29, 2018. Available: 10.5120/ijca2018917395.\n",
    "\n",
    "[2] \"Recommendation system Based On Cosine Similarity Algorithm\", International Journal of Recent Trends in Engineering and Research, vol. 3, no. 9, pp. 6-10, 2017. Available: 10.23883/ijrter.2017.3423.iss9x.\n",
    "\n",
    "[3] B. Trstenjak, S. Mikac and D. Donko, \"KNN with TF-IDF based Framework for Text Categorization\", Procedia Engineering, vol. 69, pp. 1356-1364, 2014. Available: 10.1016/j.proeng.2014.03.129.\n",
    "\n",
    "[4] \"Singular Value Decomposition\", Iridl.ldeo.columbia.edu, 2020. [Online]. Available: http://iridl.ldeo.columbia.edu/dochelp/StatTutorial/SVD/index.html. [Accessed: 20- Jul- 2020].\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
